\documentclass{article}

\usepackage[final]{neurips_2023}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors


\title{nnUNet Segmentation on Hippocampus MRI}
\author{
  Ziyao Wang\\
  73752594\\
  \texttt{ziywang@student.ubc.ca} \\
}

\begin{document}

\maketitle

\begin{abstract}
  The nnUNet is a CNN-based semantic segmentation method that is designed to work out-of-the-box in biomedical domain. It can automatically adapt to the given dataset and configure a corresponding U-Net segmentation pipeline, and is therefore widely adopted by medical imaging scientists. In this way, however, nnUNet trades customization for generalization and may not perform good enough in a specific dataset. In the report, we use nnUNet to segment hippocampus MRI images and modify its code to expect an improvement in the training accuracy and training time. We conclude that placing activation function before batch normalization in nnUNet achieves faster training with slightly better accuracy for hippocampus MRI. Also, early stop can be introduced in nnUNet training process to reduce overfitting for a relatively small dataset.
\end{abstract}


\section{Introduction}

The nnUNet is a CNN-based semantic segmentation method that is designed to work out-of-the-box in biomedical domain. Given a new dataset, nnUNet will first analyze it and extract its properties such as size, resolution, and foreground intensity as a dataset fingerprint. Then, it creates several configurations for the dataset, namely \texttt{2D}, \texttt{3D\_fullres}, and \texttt{3D\_fullres\_cascade}. After that, it set model parameters for each configuration based on the dataset fingerprint and hard-coded rules. Finally, nnUNet goes through training processes of each configuration and compares them to find the one with best validation accuracy. This whole pipeline is carried out automatically with simple CLI commands, which is good for non-experts in the machine learning field.

In this way, however, nnUNet trades customization for generalization and may not perform good enough in a specific dataset. Also, there are some unnecessary processes in the pipeline if you know the dataset well. For instance, hippocampus MRI images are all captured in 3D, and thus training with \texttt{2D} configuration is a waste of time. MRI has a typical spatial resolution \(\Delta=1\)\texttt{mm}, and specify it in the dataset will ensure parameters to be appropriate. More tuning can be made to nnUNet to segment a specific dataset.

In the report, we use the dataset of hippocampus MRI taken from Medical Segmentation Decathlon. We take half of the training set with labels as test set. The remaining half is used for training based on 5-fold cross validation. We use nnUNet to segment the dataset and modify its code to expect an improvement in the training accuracy and training time. On one hand, we swap the order of activation function and batch normalization in the neural network and observe a faster training per epoch with quite similar accuracy. On the other hand, we notice the loss function doesn't make any progress after some epochs and find that early stop can be introduced to faster terminate the training process without loss of test accuracy and reduce overfitting for this small dataset.

\section{Related work}

norm + RELU in unet

1000 epochs in nnunet

As \citet{isensee2021nnu} mentions, 


\section{What I did}

\subsection{Hippocampus}



\subsection{MRI}



\subsection{nnUNet}


\subsection{Training and Testing}



\section{Experiment and analysis}

list results as table

\subsection{norm+RELU and RELU+norm and nonorm}



\subsection{early stop of epoches based on sufficient small increment of validation loss}



\section{Discussion and future work}


conclusion, strength and weakness of my contribution, future work to be done on sth.



\subsection*{Figures}


\begin{figure}
  \centering
  \label{samplefigure}
  \fbox{\rule[-.5cm]{0cm}{4cm} \rule[-.5cm]{4cm}{0cm}}
  \caption{Sample figure caption.}
\end{figure}


\begin{table}
  \caption{Sample table title}
  \label{sample-table}
  \centering
  \begin{tabular}{lll}
    \toprule
    \multicolumn{2}{c}{Part}                   \\
    \cmidrule(r){1-2}
    Name     & Description     & Size ($\mu$m) \\
    \midrule
    Dendrite & Input terminal  & $\sim$100     \\
    Axon     & Output terminal & $\sim$10      \\
    Soma     & Cell body       & up to $10^6$  \\
    \bottomrule
  \end{tabular}
\end{table}


\section*{Supplementary Material}

CLI commands

modified codes

\bibliographystyle{abbrvnat}
\bibliography{report}


\end{document}